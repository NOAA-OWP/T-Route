{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# logic to accomodate Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    ENV_IS_CL = True\n",
    "\n",
    "    root = pathlib.Path(\"/content/t-route\").resolve()\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"git\",\n",
    "            \"clone\",\n",
    "            \"https://github.com/NOAA-OWP/t-route.git\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ! pip install geopandas\n",
    "    ! pip install netcdf4\n",
    "\n",
    "except:\n",
    "    ENV_IS_CL = False\n",
    "    root = pathlib.Path(\"..\").resolve()\n",
    "\n",
    "fortran_source_dir = os.path.join(root, \"src\", \"fortran_routing\", \"mc_pylink_v00\", \"MC_singleSeg_singleTS\")\n",
    "sys.path.append(fortran_source_dir)\n",
    "\n",
    "reservoir_source_dir = os.path.join(root, \"src\", \"fortran_routing\", \"mc_pylink_v00\", \"Reservoir_singleTS\")\n",
    "sys.path.append(reservoir_source_dir)\n",
    "\n",
    "routing_v02_dir = os.path.join(root, \"src\", \"python_routing_v02\",\"fast_reach\")\n",
    "sys.path.append(routing_v02_dir)\n",
    "\n",
    "framework_v02_dir = os.path.join(root, \"src\", \"python_framework_v02\")\n",
    "sys.path.append(framework_v02_dir)\n",
    "\n",
    "framework_v01_dir = os.path.join(root, \"src\", \"python_framework_v01\")\n",
    "sys.path.append(framework_v01_dir)\n",
    "\n",
    "# scientific packages\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from itertools import chain, islice\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# t-route functions\n",
    "import nhd_network_utilities_v02 as nnu\n",
    "import nhd_io\n",
    "import nhd_network\n",
    "import network_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile cython routing module\n",
    "- if you are running this notebook with Google Colab, the compile commands in the cell below will work. If not, you will need to compile cython scripts on your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILE_cython = True\n",
    "if ENV_IS_CL and COMPILE_cython:\n",
    "\n",
    "    # clear .so files as a matter of housekeeping\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"rm\", \n",
    "            \"*.so\"\n",
    "        ],\n",
    "        cwd=routing_v02_dir,\n",
    "    )\n",
    "    \n",
    "    # compile vaPrecision.f90\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gfortran\", \n",
    "            \"varPrecision.f90\", \n",
    "            \"-c\", \n",
    "            \"-O0\", \n",
    "            \"-fPIC\"],\n",
    "        cwd=fortran_source_dir,\n",
    "    )\n",
    "\n",
    "    # compile MCsingleSegStime_f2py_NOLOOP.f90\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gfortran\",\n",
    "            \"-c\",\n",
    "            \"-O0\",\n",
    "            \"-fPIC\",\n",
    "            \"-o\",\n",
    "            \"mc_single_seg.o\",\n",
    "            \"MCsingleSegStime_f2py_NOLOOP.f90\"\n",
    "        ],\n",
    "        cwd=fortran_source_dir,\n",
    "    )\n",
    "\n",
    "    # compile pyMCsingleSegStime_NoLoop.f90\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gfortran\",\n",
    "            \"pyMCsingleSegStime_NoLoop.f90\",\n",
    "            \"-c\",\n",
    "            \"-o\",\n",
    "            \"pymc_single_seg.o\",\n",
    "            \"-O3\",\n",
    "            \"-fPIC\"\n",
    "        ],\n",
    "        cwd=fortran_source_dir,\n",
    "    )\n",
    "\n",
    "    # copy *.o files to python_routing_v02/fast_reach \n",
    "    for obj_file in glob.glob(os.path.join(fortran_source_dir, \"*.o\")):\n",
    "        print(obj_file)\n",
    "        subprocess.run([\"cp\", obj_file, routing_v02_dir])    \n",
    "\n",
    "    # compile vaPrecision.f90\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gfortran\", \n",
    "            \"varPrecision.f90\", \n",
    "            \"-c\", \n",
    "            \"-O0\", \n",
    "            \"-fPIC\"],\n",
    "        cwd=reservoir_source_dir,\n",
    "    )\n",
    "\n",
    "    # compile module_levelpool.f90\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gfortran\",\n",
    "            \"-c\",\n",
    "            \"-O2\",\n",
    "            \"-fPIC\",\n",
    "            \"-o\",\n",
    "            \"module_levelpool.o\",\n",
    "            \"module_levelpool.f90\"\n",
    "        ],\n",
    "        cwd=reservoir_source_dir,\n",
    "    )\n",
    "\n",
    "    # compile pymodule_levelpool.f90\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gfortran\",\n",
    "            \"-c\",\n",
    "            \"-O2\",\n",
    "            \"-fPIC\",\n",
    "            \"-o\",\n",
    "            \"pymodule_levelpool.o\",\n",
    "            \"pymodule_levelpool.f90\"\n",
    "        ],\n",
    "        cwd=reservoir_source_dir,\n",
    "    ) \n",
    "\n",
    "    # copy *.o files to python_routing_v02/fast_reach \n",
    "    for obj_file in glob.glob(os.path.join(reservoir_source_dir, \"*.o\")):\n",
    "        print(obj_file)\n",
    "        subprocess.run([\"cp\", obj_file, routing_v02_dir])\n",
    "\n",
    "    numpy_I = \"/usr/local/lib/python3.6/dist-packages/numpy/core/include\"\n",
    "    py_I = \"/usr/include/python3.6\"\n",
    "    py_lib = \"/usr/include/python3.6\" \n",
    "\n",
    "    # for unknown reasons this line does not work with subprocess.run\n",
    "    %cd \"/content/t-route/src/python_routing_v02/fast_reach\"\n",
    "    ! cython -3 -v -p --gdb --line-directives -Wextra --cleanup 3 fortran_wrappers.pxd *.pyx\n",
    "\n",
    "    file = [\"fortran_wrappers\",\"mc_reach\",\"reservoir\",\"reach\",\"utils\"]\n",
    "    for f in file:\n",
    "        subprocess.run(\n",
    "          [\n",
    "              \"gcc\",\n",
    "              \"-pthread\",\n",
    "              \"-Wno-unused-result\",\n",
    "              \"-Wsign-compare\",\n",
    "              \"-DNDEBUG\",\n",
    "              \"-fwrapv\",\n",
    "              \"-O2\",\n",
    "              \"-Wall\",\n",
    "              \"-Wstrict-prototypes\",\n",
    "              \"-fPIC\",\n",
    "              \"-fopenmp\",\n",
    "              \"-fno-strict-aliasing\",\n",
    "              \"-I\",\n",
    "              numpy_I,\n",
    "              \"-I\",\n",
    "              py_I,\n",
    "              \"-mtune=generic\",\n",
    "              \"-c\",\n",
    "              \"-o\",\n",
    "              f + \".o\",\n",
    "              f + \".c\"\n",
    "          ],\n",
    "          cwd=routing_v02_dir,\n",
    "        )\n",
    "\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gcc\",\n",
    "            \"-pthread\",\n",
    "            \"-fopenmp\",\n",
    "            \"-shared\", \n",
    "            \"-L\",\n",
    "            py_lib, \n",
    "            \"-lgfortran\",\n",
    "            \"-o\",\n",
    "            \"reach.cpython-36m-x86_64-linux-gnu.so\",\n",
    "            \"mc_single_seg.o\",\n",
    "            \"pymc_single_seg.o\",\n",
    "            \"fortran_wrappers.o\",\n",
    "            \"reach.o\"\n",
    "        ],\n",
    "        cwd=routing_v02_dir,\n",
    "    )\n",
    "\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gcc\",\n",
    "            \"-pthread\",\n",
    "            \"-fopenmp\",\n",
    "            \"-shared\", \n",
    "            \"-L\",\n",
    "            py_lib, \n",
    "            \"-lgfortran\",\n",
    "            \"-o\",\n",
    "            \"reservoir.cpython-36m-x86_64-linux-gnu.so\",\n",
    "            \"module_levelpool.o\",\n",
    "            \"pymodule_levelpool.o\",\n",
    "            \"fortran_wrappers.o\",\n",
    "            \"reservoir.o\"\n",
    "        ],\n",
    "        cwd=routing_v02_dir,\n",
    "    )\n",
    "\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gcc\",\n",
    "            \"-pthread\",\n",
    "            \"-fopenmp\",\n",
    "            \"-shared\", \n",
    "            \"-L\",\n",
    "            py_lib, \n",
    "            \"-o\",\n",
    "            \"mc_reach.cpython-36m-x86_64-linux-gnu.so\",\n",
    "            \"mc_reach.o\"\n",
    "        ],\n",
    "        cwd=routing_v02_dir,\n",
    "    )\n",
    "\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"gcc\",\n",
    "            \"-pthread\",\n",
    "            \"-fopenmp\",\n",
    "            \"-shared\", \n",
    "            \"-L\",\n",
    "            py_lib, \n",
    "            \"-o\",\n",
    "            \"utils.cpython-36m-x86_64-linux-gnu.so\",\n",
    "            \"utils.o\"\n",
    "        ],\n",
    "        cwd=routing_v02_dir,\n",
    "    )\n",
    "else:\n",
    "    os.chdir(routing_v02_dir)\n",
    "    ! ./cython_compile.sh\n",
    "    os.chdir(os.path.join(root,\"notebooks\"))\n",
    "    \n",
    "import mc_reach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supernetwork connections for Pocono_TEST2 domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Identifying supernetwork connections set\")\n",
    "\n",
    "test_folder = os.path.join(root, r\"test\")\n",
    "geo_input_folder = os.path.join(test_folder, r\"input\", r\"geo\")\n",
    "supernetwork = \"Pocono_TEST2\"\n",
    "\n",
    "network_data = nnu.set_supernetwork_data(\n",
    "    supernetwork=supernetwork, geo_input_folder=geo_input_folder\n",
    ")\n",
    "\n",
    "# if the NHDPlus RouteLink file does not exist, download it.\n",
    "if not os.path.exists(network_data[\"geo_file_path\"]):\n",
    "    filename = os.path.basename(network_data[\"geo_file_path\"])\n",
    "    network_dl.download(network_data[\"geo_file_path\"], network_data[\"data_link\"])\n",
    "\n",
    "# select only the necessary columns of geospatial data, set the DataFrame index\n",
    "cols = [v for c, v in network_data[\"columns\"].items()]\n",
    "data = nhd_io.read(network_data[\"geo_file_path\"])\n",
    "data = data[cols]\n",
    "data = data.set_index(network_data[\"columns\"][\"key\"])\n",
    "\n",
    "# mask NHDNetwork to isolate test network of choice\n",
    "if \"mask_file_path\" in network_data:\n",
    "    data_mask = nhd_io.read_mask(\n",
    "        network_data[\"mask_file_path\"], layer_string=network_data[\"mask_layer_string\"],\n",
    "    )\n",
    "    data = data.filter(data_mask.iloc[:, network_data[\"mask_key\"]], axis=0)\n",
    "\n",
    "# sort index\n",
    "data = data.sort_index()\n",
    "\n",
    "# replace downstreams\n",
    "data = nhd_io.replace_downstreams(data, network_data[\"columns\"][\"downstream\"], 0)\n",
    "\n",
    "# extract downstream connections for each node\n",
    "connections = nhd_network.extract_connections(data, network_data[\"columns\"][\"downstream\"])\n",
    "\n",
    "print(\"supernetwork connections set created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize supernetwork into subnetworks and reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Organizing segments into reaches.\")\n",
    "\n",
    "# reverse the network - track upstream connections\n",
    "rconn = nhd_network.reverse_network(connections)\n",
    "\n",
    "# isolate independent subnetworks\n",
    "subnets = nhd_network.reachable_network(rconn)\n",
    "\n",
    "# identify the segments in each subnetwork\n",
    "subreachable = nhd_network.reachable(rconn)\n",
    "\n",
    "# break each subnetwork into reaches\n",
    "subreaches = {}\n",
    "for tw, net in subnets.items():\n",
    "    path_func = partial(nhd_network.split_at_junction, net)\n",
    "    subreaches[tw] = nhd_network.dfs_decomposition(net, path_func)\n",
    "\n",
    "print(\"Reach creation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load lateral inflow data from WRF-Hydro CHRTOUT files\n",
    "- CHRTOUT files contain the states and fluxes output from the WRF Hydro model. One such flux term is the magnitude of lateral inflows to each node in the stream network. \n",
    "- A python function, `nhd_io.get_ql_from_wrf_hydro`, reads lateral inflow data from CHRTOUT files, provided a list of file paths.\n",
    "- A single CHRTOUT file is generated for each WRF-simulated timestep. The number of columns in the lateral inflow DataFrame will be equal to the number of file paths handed to `nhd_io.get_ql_from_wrf_hydro` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CHRTOUT file paths\n",
    "path = os.path.join(root, \"test\",\"input\",\"geo\",\"NWM_2.1_Sample_Datasets\",\"Pocono_TEST1\",\"example_CHRTOUT\")\n",
    "qlat_files = glob.glob(path + \"/*\", recursive=True)\n",
    "\n",
    "ql = nhd_io.get_ql_from_wrf_hydro(qlat_files,index_col=\"feature_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load initial conditions from WRF-hydro HYDRO_RST file\n",
    "- The HYDRO_RST file contains the initial states of the WRF Hydro model. Initial flow and depth conditions are needed to initialize our routing model. \n",
    "- A python function, `nhd_io.get_stream_restart_from_wrf_hydro`, reads initial flow and depth states from the HYDRO_RST file. Function inputs are 1) the file path of the HYDRO_RST file, 2) the file path of a \"crosswalk\" file, and 3) the field name of the index variable in the crosswalk data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrf_hydro_channel_restart_file = os.path.join(root, \"test\", \"input\",\"geo\",\"NWM_2.1_Sample_Datasets\",\"Pocono_TEST1\",\"example_RESTART\",\n",
    "                    \"HYDRO_RST.2017-12-31_06-00_DOMAIN1\")\n",
    "wrf_hydro_channel_ID_crosswalk_file = os.path.join(root, \"test\", \"input\",\"geo\",\"NWM_2.1_Sample_Datasets\",\"Pocono_TEST1\",\"primary_domain\",\n",
    "                    \"DOMAIN\",\"Route_Link.nc\")\n",
    "wrf_hydro_channel_ID_crosswalk_file_field_name = \"link\"\n",
    "\n",
    "q0 = nhd_io.get_stream_restart_from_wrf_hydro(\n",
    "    wrf_hydro_channel_restart_file,\n",
    "    wrf_hydro_channel_ID_crosswalk_file,\n",
    "    wrf_hydro_channel_ID_crosswalk_file_field_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up routing simulation time domain\n",
    "- The routing simulation must have a total duration less than of equal to that of the WRF-Hydro simulation. \n",
    "- In the cell below, the timestep of the routing simulation is provided and the number of timesteps in the routing model is calculated such that the duration of the routing simulation matches that of the WRT-Hydro simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 5*60  # routing simulation timestep (seconds) \n",
    "\n",
    "dt_routing = pd.Timedelta(str(dt) + 'seconds')\n",
    "wrf_time = ql.columns.astype(\"datetime64[ns]\")\n",
    "dt_wrf = (wrf_time[1] - wrf_time[0])\n",
    "sim_duration = (wrf_time[-1] + dt_wrf) - wrf_time[0]\n",
    "\n",
    "nts = round(sim_duration / dt_routing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the routing module - with original ordering scheme and serial computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a results matrix\n",
    "results = []\n",
    "\n",
    "# Specify the tailwater of the the test basin\n",
    "tw = 4186169\n",
    "reach = subreaches[tw]\n",
    "\n",
    "# get a list of segments in the subnetwork\n",
    "r = list(filter(None, chain.from_iterable(reach)))\n",
    "\n",
    "# add a dt column to the data DataFrame\n",
    "data[\"dt\"] = dt\n",
    "\n",
    "# rename columns to specific variable names expected by mc_reach.compute_network\n",
    "column_rename = {\n",
    "    network_data[\"columns\"][\"dx\"]: \"dx\",\n",
    "    network_data[\"columns\"][\"tw\"]: \"tw\",\n",
    "    network_data[\"columns\"][\"twcc\"]: \"twcc\",\n",
    "    network_data[\"columns\"][\"bw\"]: \"bw\",\n",
    "    network_data[\"columns\"][\"ncc\"]: \"ncc\",\n",
    "    network_data[\"columns\"][\"s0\"]: \"s0\",\n",
    "    network_data[\"columns\"][\"cs\"]: \"cs\",\n",
    "    network_data[\"columns\"][\"n\"]: \"n\",\n",
    "}\n",
    "\n",
    "data = data.rename(columns=column_rename)\n",
    "\n",
    "# change variables to type float32, as expected by mc_reach.compute_network\n",
    "data = data.astype(\"float32\")\n",
    "\n",
    "# prep parameter, lateral inflow, and initial condition data to be fed to routing model\n",
    "data_sub = data.loc[\n",
    "    r, [\"dt\", \"bw\", \"tw\", \"twcc\", \"dx\", \"n\", \"ncc\", \"cs\", \"s0\"]\n",
    "].sort_index()\n",
    "\n",
    "# prep lateral inflow data\n",
    "qlat_sub = ql.loc[r].sort_index()\n",
    "\n",
    "\n",
    "# prep initial conditions data\n",
    "q0_sub = q0.loc[r].sort_index()\n",
    "\n",
    "# compute the network routing, calculate (flow, depth, and velocity)\n",
    "results.append(\n",
    "    mc_reach.compute_network(\n",
    "        nsteps = nts,\n",
    "        reaches = reach,\n",
    "        connections = subnets[tw],\n",
    "        data_idx = data_sub.index.values,\n",
    "        data_cols = data_sub.columns.values,\n",
    "        data_values = data_sub.values.astype(\"float32\"),\n",
    "        qlat_values = qlat_sub.values.astype(\"float32\"),\n",
    "        initial_conditions = q0_sub.values.astype(\"float32\"), # !! pass initial conditions, here !!\n",
    "        assume_short_ts = True\n",
    "    )\n",
    ")\n",
    "\n",
    "# create a multi-index DataFrame with flow, depth, and velocity simulations\n",
    "fdv_columns = pd.MultiIndex.from_product([range(nts), [\"q\", \"v\", \"d\"]])\n",
    "flowveldepth = pd.concat(\n",
    "    [pd.DataFrame(d, index=i, columns=fdv_columns) for i, d in results], copy=False\n",
    ")\n",
    "flowveldepth = flowveldepth.sort_index()\n",
    "\n",
    "flows = flowveldepth.loc[:, (slice(None), \"q\")]\n",
    "flows = flows.T.reset_index(level = [0,1])\n",
    "flows.rename(columns = {\"level_0\": \"Timestep\", \"level_1\": \"Parameter\"}, inplace = True)\n",
    "flows['Time (d)'] = ((flows.Timestep + 1) * dt)/(24*60*60)\n",
    "flows = flows.set_index('Time (d)')\n",
    "\n",
    "vel = flowveldepth.loc[:, (slice(None), \"v\")]\n",
    "vel = vel.T.reset_index(level = [0,1])\n",
    "vel.rename(columns = {\"level_0\": \"Timestep\", \"level_1\": \"Parameter\"}, inplace = True)\n",
    "vel['Time (d)'] = ((vel.Timestep + 1) * dt)/(24*60*60)\n",
    "vel = vel.set_index('Time (d)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the routing module - with modified ordering and multithreading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_reaches = {}\n",
    "for tw, net in subnets.items():\n",
    "    path_func = partial(nhd_network.split_at_junction, net)\n",
    "    tuple_reaches[tw] = nhd_network.dfs_decomposition_depth_tuple(net, path_func)\n",
    "\n",
    "# convert tuple_reaches (dict) to a (list)\n",
    "overall_tuple_reaches = []\n",
    "for keys, tuple_list in tuple_reaches.items():\n",
    "    if keys == 4186169: # <---- this is the network tailwater segment\n",
    "        overall_tuple_reaches.extend(tuple_list)\n",
    "\n",
    "# create a dict with key = reach order, and values are segments in each reach of the corresponding order\n",
    "overall_ordered_reaches_dict = nhd_network.tuple_with_orders_into_dict(overall_tuple_reaches)\n",
    "max_order = max(overall_ordered_reaches_dict.keys())\n",
    "\n",
    "overall_ordered_reaches_list = []\n",
    "ordered_reach_count = []\n",
    "ordered_reach_cache_count = []\n",
    "for o in range(max_order,-1,-1):\n",
    "    overall_ordered_reaches_list.extend(overall_ordered_reaches_dict[o])\n",
    "    ordered_reach_count.append(len(overall_ordered_reaches_dict[o]))\n",
    "    ordered_reach_cache_count.append(sum(len(r) for r in overall_ordered_reaches_dict[o]))\n",
    "    \n",
    "rconn_ordered = {}\n",
    "rconn_ordered_byreach = {}\n",
    "for o in range(max(overall_ordered_reaches_dict.keys()),-1,-1):\n",
    "    rconn_ordered[o] = {}\n",
    "    for reach in overall_ordered_reaches_dict[o]:\n",
    "        for segment in reach:\n",
    "            rconn_ordered[o][segment] = rconn[segment]\n",
    "            rconn_ordered_byreach[segment] = rconn[segment]\n",
    "                       \n",
    "# prep parameter, lateral inflow, and initial condition data to be fed to routing model\n",
    "r = list(chain.from_iterable(overall_ordered_reaches_list))\n",
    "data_sub = data.loc[\n",
    "    r, [\"dt\", \"bw\", \"tw\", \"twcc\", \"dx\", \"n\", \"ncc\", \"cs\", \"s0\"]\n",
    "].sort_index()\n",
    "# prep lateral inflow data\n",
    "qlat_sub = ql.loc[r].sort_index()\n",
    "# prep initial conditions data\n",
    "q0_sub = q0.loc[r].sort_index()\n",
    "\n",
    "results = []\n",
    "results.append(\n",
    "    mc_reach.compute_network_multithread(\n",
    "        nts,\n",
    "        overall_ordered_reaches_list,\n",
    "        rconn_ordered_byreach,\n",
    "        data_idx = data_sub.index.values,\n",
    "        data_cols = data_sub.columns.values,\n",
    "        data_values = data_sub.values.astype(\"float32\"),\n",
    "        qlat_values = qlat_sub.values.astype(\"float32\"),\n",
    "        initial_conditions = q0_sub.values.astype(\"float32\"), # !! pass initial conditions, here !!\n",
    "        reach_groups = np.array(ordered_reach_count, dtype=\"int32\"),\n",
    "        reach_group_cache_sizes = np.array(ordered_reach_cache_count, dtype=\"int32\"),\n",
    "        assume_short_ts = True\n",
    "    )\n",
    ")\n",
    "\n",
    "# create a multi-index DataFrame with flow, depth, and velocity simulations\n",
    "fdv_columns = pd.MultiIndex.from_product([range(nts), [\"q\", \"v\", \"d\"]])\n",
    "flowveldepth = pd.concat(\n",
    "    [pd.DataFrame(d, index=i, columns=fdv_columns) for i, d in results], copy=False\n",
    ")\n",
    "flowveldepth = flowveldepth.sort_index()\n",
    "\n",
    "flows_reorder = flowveldepth.loc[:, (slice(None), \"q\")]\n",
    "flows_reorder = flows_reorder.T.reset_index(level = [0,1])\n",
    "flows_reorder.rename(columns = {\"level_0\": \"Timestep\", \"level_1\": \"Parameter\"}, inplace = True)\n",
    "flows_reorder['Time (d)'] = ((flows_reorder.Timestep + 1) * dt)/(24*60*60)\n",
    "flows_reorder = flows_reorder.set_index('Time (d)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare t-route simulated flow against WRF Hydro simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get WRF-simulated flow, velocity and depth\n",
    "index_col = \"feature_id\"\n",
    "\n",
    "li = []\n",
    "for filename in qlat_files:\n",
    "    with xr.open_dataset(filename) as ds:\n",
    "        df1 = ds.to_dataframe()\n",
    "        \n",
    "    li.append(df1)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=False)\n",
    "mod = frame.reset_index()\n",
    "flow_wrf = mod.pivot(index=index_col, columns=\"time\", values=\"streamflow\")\n",
    "\n",
    "# specify calendar times for each simulation\n",
    "time_routing = pd.period_range((wrf_time[0]-dt_wrf+dt_routing), periods=nts, freq=dt_routing).astype(\"datetime64[ns]\")\n",
    "time_wrf = flow_wrf.columns.values\n",
    "\n",
    "# plot t-route and WRF simulated flows\n",
    "compare_node = 4186169\n",
    "\n",
    "plt.plot(time_wrf,flow_wrf.loc[compare_node ,:],'.', label = \"wrf simulation\")\n",
    "plt.plot(time_routing,flows_reorder.loc[:,compare_node ], '-', label = \"v02 simulation, multithreaded\")\n",
    "plt.ylabel(\"Flow (cms)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.autofmt_xdate()\n",
    "plt.show()\n",
    "\n",
    "# print flow values at common timesteps\n",
    "# create table of flow results at common timesteps\n",
    "trt = pd.DataFrame(flows.loc[:,compare_node ].values, index = time_routing, columns = [\"flow, t-route (cms)\"])\n",
    "trt_re = pd.DataFrame(flows_reorder.loc[:,compare_node ].values, index = time_routing, columns = [\"flow, t-route, multithreaded (cms)\"])\n",
    "wrf = pd.DataFrame(flow_wrf.loc[compare_node ,:].values, index = time_wrf, columns = [\"flow, wrf (cms)\"])\n",
    "\n",
    "compare = pd.concat([wrf, trt, trt_re], axis=1, sort=False, join = 'inner')\n",
    "\n",
    "# compare[\"diff (cms)\"] = (compare[\"flow, t-route (cms)\"] - compare[\"flow, wrf (cms)\"])\n",
    "\n",
    "display(HTML(compare.to_html()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
